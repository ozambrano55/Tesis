
\chapter{Anexos}
\section{Anexo A: Diccionario de Datos del Data Warehouse}

\subsection{A.1 Esquema DIM - Dimensiones}

\subsubsection{DimTiempo}

Dimensión calendario que proporciona desagregación temporal desde nivel día hasta nivel año. Generada automáticamente para el período 2020-2030.

\begin{longtable}{|p{4cm}|p{3cm}|p{6cm}|}
\caption{Estructura de la tabla dim.DimTiempo} \\
\hline
\textbf{Campo} & \textbf{Tipo} & \textbf{Descripción} \\
\hline
\endfirsthead
\hline
\textbf{Campo} & \textbf{Tipo} & \textbf{Descripción} \\
\hline
\endhead
TiempoKey & INT & Clave subrogada (PK). Formato: YYYYMMDD \\
\hline
Fecha & DATE & Fecha real del calendario \\
\hline
Anio & INT & Año (2020-2030) \\
\hline
Mes & INT & Mes (1-12) \\
\hline
MesNombre & VARCHAR(20) & Nombre del mes en español \\
\hline
Dia & INT & Día del mes (1-31) \\
\hline
DiaSemana & INT & Día de la semana (1=Lunes, 7=Domingo) \\
\hline
DiaSemananombre & VARCHAR(20) & Nombre del día en español \\
\hline
Trimestre & INT & Trimestre del año (1-4) \\
\hline
Semana & INT & Semana del año (1-53) \\
\hline
PeriodoAnioMes & VARCHAR(7) & Formato YYYY-MM para agrupación \\
\hline
EsDiaLaboral & BIT & 1 = Día laboral, 0 = Fin de semana/festivo \\
\hline
EsFeriado & BIT & 1 = Día festivo oficial Ecuador \\
\hline
NombreFeriado & VARCHAR(100) & Nombre del festivo si aplica \\
\hline
\end{longtable}

\textbf{Observaciones:} La tabla contiene 5,844 registros correspondientes a todos los días del período 2015-2024. Los festivos de Ecuador fueron incorporados manualmente siguiendo el calendario oficial.

\subsubsection{DimCliente}

Dimensión que contiene el maestro de clientes con implementación SCD Tipo 2 para rastrear cambios históricos.

\begin{longtable}{|p{4cm}|p{3cm}|p{8cm}|}
\caption{Estructura de la tabla dim.DimCliente (campos principales)} \\
\hline
\textbf{Campo} & \textbf{Tipo} & \textbf{Descripción} \\
\hline
\endfirsthead
\hline
\textbf{Campo} & \textbf{Tipo} & \textbf{Descripción} \\
\hline
\endhead
ClienteKey & INT & Clave subrogada (PK) auto-incremental \\
\hline
C\_Cod\_Cliente & INT & Código de cliente en sistema origen \\
\hline
Cliente & VARCHAR(200) & Nombre completo del cliente \\
\hline
D\_Razon\_Social & VARCHAR(200) & Razón social para personas jurídicas \\
\hline
C\_Tipo\_Identi & VARCHAR(10) & Tipo de identificación (RUC/CI/PASS) \\
\hline
Num\_Identi & VARCHAR(20) & Número de identificación \\
\hline
C\_Regional & INT & Código de regional asignado \\
\hline
Regional & VARCHAR(100) & Nombre de la regional \\
\hline
C\_Zona\_Geo & INT & Código de zona geográfica \\
\hline
D\_Zona\_Geo & VARCHAR(100) & Descripción de zona geográfica \\
\hline
C\_Vendedor & INT & Código del vendedor asignado \\
\hline
Vendedor & VARCHAR(200) & Nombre del vendedor \\
\hline
C\_Lider & INT & Código del líder comercial \\
\hline
Lider & VARCHAR(200) & Nombre del líder \\
\hline
C\_Director & INT & Código del director regional \\
\hline
Director & VARCHAR(200) & Nombre del director \\
\hline
Cupo\_Facturacion & DECIMAL(18,2) & Cupo de crédito autorizado \\
\hline
V\_Dias\_Pago & INT & Plazo de pago en días \\
\hline
C\_Tipo\_Cliente & INT & Código de tipo/categoría cliente \\
\hline
Flag\_Vigente & BIT & 1 = Cliente activo, 0 = Inactivo \\
\hline
F\_Ingreso & DATE & Fecha de ingreso como cliente \\
\hline
\multicolumn{3}{|c|}{\textit{Campos SCD Tipo 2}} \\
\hline
FechaInicioVigencia & DATETIME2 & Timestamp inicio vigencia registro \\
\hline
FechaFinVigencia & DATETIME2 & Timestamp fin vigencia (NULL = actual) \\
\hline
EsRegistroActual & BIT & 1 = Versión actual, 0 = Histórico \\
\hline
\end{longtable}

\textbf{Observaciones:} La dimensión contiene 1,407 registros activos (EsRegistroActual = 1) más 156 registros históricos producto de cambios detectados durante el período analizado.

\textbf{Regla SCD Tipo 2:} Cuando se detecta un cambio en algún campo descriptivo (nombre, dirección, vendedor asignado, cupo, etc.), el sistema marca el registro anterior como no vigente estableciendo FechaFinVigencia = GETDATE() y EsRegistroActual = 0, luego inserta un nuevo registro con los valores actualizados.

\subsubsection{DimProducto}

Dimensión del catálogo de productos con clasificación por grupos, subgrupos y líneas.

\begin{longtable}{|p{4cm}|p{3cm}|p{8cm}|}
\caption{Estructura de la tabla dim.DimProducto (campos principales)} \\
\hline
\textbf{Campo} & \textbf{Tipo} & \textbf{Descripción} \\
\hline
\endfirsthead
\hline
\textbf{Campo} & \textbf{Tipo} & \textbf{Descripción} \\
\hline
\endhead
ProductoKey & INT & Clave subrogada (PK) \\
\hline
C\_Item & VARCHAR(20) & Código de producto \\
\hline
N\_Producto\_Terminado & VARCHAR(200) & Descripción del producto \\
\hline
C\_Grupo & INT & Código de grupo principal \\
\hline
D\_Grupo & VARCHAR(100) & Descripción del grupo (Juguetería, Hogar, etc.) \\
\hline
C\_Subgrupo & INT & Código de subgrupo \\
\hline
D\_Subgrupo & VARCHAR(100) & Descripción del subgrupo \\
\hline
C\_Linea\_Venta & INT & Código de línea de venta \\
\hline
D\_Linea\_Venta & VARCHAR(100) & Descripción de línea de venta \\
\hline
\multicolumn{3}{|c|}{\textit{Campos SCD Tipo 2}} \\
\hline
FechaInicioVigencia & DATETIME2 & Timestamp inicio vigencia \\
\hline
FechaFinVigencia & DATETIME2 & Timestamp fin vigencia \\
\hline
EsRegistroActual & BIT & Indicador registro actual \\
\hline
\end{longtable}

\textbf{Observaciones:} Contiene 4,127 productos activos organizados en 4 grupos principales (Juguetería, Hogar, Aseo, Cocina), 47 subgrupos y 156 líneas de venta.
\section{Anexo A: Código Fuente del Modelo Predictivo}

A continuación, se presenta el código principal para el entrenamiento del modelo XGBoost utilizado en el proyecto:

\begin{verbatim}
# Importación de librerías
import pandas as pd
import numpy as np
import pyodbc
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns

# Conexión a SQL Server 2022
def conectar_sql_server():
    server = 'servidor-sqlserver'
    database = 'DW_Comisaseo'
    username = 'usuario_analisis'
    password = 'password'
    
    connection_string = f'''
    DRIVER={{ODBC Driver 17 for SQL Server}};
    SERVER={server};
    DATABASE={database};
    UID={username};
    PWD={password}
    '''
    
    conn = pyodbc.connect(connection_string)
    return conn

# Cargar datos desde SQL Server
def cargar_datos():
    conn = conectar_sql_server()
    
    query = """
    SELECT 
        ID_Cliente,
        Region,
        Antiguedad_Meses,
        Promedio_Compra_Mensual,
        Frecuencia_Compra_Mensual,
        Dias_Promedio_Pago,
        Maximo_Dias_Atraso,
        Porcentaje_Devoluciones,
        Indice_Estacionalidad,
        Ratio_Pago_Plazo,
        Variabilidad_Pago,
        Indice_Concentracion_Producto,
        Tendencia_Compra,
        Indice_Cumplimiento,
        Moroso
    FROM V_Datos_ML
    """
    
    df = pd.read_sql(query, conn)
    conn.close()
    return df

# Cargar datos
df = cargar_datos()

# Definición de variables predictoras y objetivo
X = df.drop(['ID_Cliente', 'Moroso'], axis=1)
y = df['Moroso']

# División de conjunto de datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y)

# Identificación de columnas por tipo
cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()

# Definición de preprocesador
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ])

# Definición de pipeline con XGBoost
xgb_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', xgb.XGBClassifier(objective='binary:logistic', random_state=42))
])

# Definición de parámetros para optimización
param_grid = {
    'classifier__n_estimators': [100, 200, 300],
    'classifier__max_depth': [3, 5, 7],
    'classifier__learning_rate': [0.01, 0.1, 0.2],
    'classifier__subsample': [0.8, 0.9, 1.0],
    'classifier__colsample_bytree': [0.8, 0.9, 1.0]
}

# Búsqueda de mejores hiperparámetros
grid_search = GridSearchCV(
    xgb_pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2
)
grid_search.fit(X_train, y_train)

# Mejores parámetros encontrados
print("Mejores parámetros:", grid_search.best_params_)

# Evaluación del modelo con mejores parámetros
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
y_pred_proba = best_model.predict_proba(X_test)[:, 1]

# Métricas de evaluación
print("\nInforme de clasificación:")
print(classification_report(y_test, y_pred))

print("\nMatriz de confusión:")
conf_matrix = confusion_matrix(y_test, y_pred)
print(conf_matrix)

print("\nÁrea bajo la curva ROC:")
roc_auc = roc_auc_score(y_test, y_pred_proba)
print(roc_auc)

# Guardar predicciones en SQL Server
def guardar_predicciones(modelo, datos, probabilidades):
    conn = conectar_sql_server()
    cursor = conn.cursor()
    
    for i, (id_cliente, prob) in enumerate(zip(datos['ID_Cliente'], probabilidades)):
        nivel_alerta = 'Verde'
        if prob > 0.75:
            nivel_alerta = 'Rojo'
        elif prob > 0.50:
            nivel_alerta = 'Naranja'
        elif prob > 0.20:
            nivel_alerta = 'Amarillo'
        
        query = """
        INSERT INTO ML_Predicciones 
        (ID_Cliente, Fecha_Prediccion, Probabilidad_Morosidad, Nivel_Alerta, Score_Riesgo)
        VALUES (?, GETDATE(), ?, ?, ?)
        """
        
        cursor.execute(query, (int(id_cliente), float(prob), nivel_alerta, int(prob * 100)))
    
    conn.commit()
    cursor.close()
    conn.close()
    print("Predicciones guardadas en SQL Server")

# Guardar modelo entrenado
import joblib
joblib.dump(best_model, 'modelo_xgboost_final.pkl')
print("\nModelo guardado como 'modelo_xgboost_final.pkl'")

# Guardar predicciones en base de datos
guardar_predicciones(best_model, df, y_pred_proba)
\end{verbatim}
\newpage
\section{Anexo B: Procedimientos Almacenados del Sistema ETL}

\subsection{B.1 Procedimiento Maestro de Carga de Dimensiones}

\begin{lstlisting}[
    language=SQL,
    caption={Procedimiento dim.sp\_CargarTodasDimensiones},
    label={lst:sp_cargar_dims}
]
CREATE PROCEDURE dim.sp_CargarTodasDimensiones
AS
BEGIN
    SET NOCOUNT ON;
    
    DECLARE @LogID INT;
    
    -- Registrar inicio de ejecucion
    INSERT INTO etl.LogEjecucion (
        ProcesoNombre, FechaInicio, Estado
    )
    VALUES (
        'Carga Todas Dimensiones',
        GETDATE(),
        'En Proceso'
    );
    
    SET @LogID = SCOPE_IDENTITY();
    
    BEGIN TRY
        -- Ejecutar procedimientos en orden
        PRINT 'Iniciando carga de dimensiones...';
        
        PRINT 'Cargando DimTiempo...';
        EXEC dim.sp_CargarDimTiempo;
        
        PRINT 'Cargando DimCliente...';
        EXEC dim.sp_CargarDimCliente;
        
        PRINT 'Cargando DimProducto...';
        EXEC dim.sp_CargarDimProducto;
        
        PRINT 'Cargando DimPuntoVenta...';
        EXEC dim.sp_CargarDimPuntoVenta;
        
        PRINT 'Cargando DimCampana...';
        EXEC dim.sp_CargarDimCampana;
        
        PRINT 'Cargando DimTipoPago...';
        EXEC dim.sp_CargarDimTipoPago;
        
        PRINT 'Cargando DimEstado...';
        EXEC dim.sp_CargarDimEstado;
        
        -- Actualizar log de ejecucion
        UPDATE etl.LogEjecucion
        SET Estado = 'Completado',
            FechaFin = GETDATE(),
            DuracionSegundos = 
                DATEDIFF(SECOND, FechaInicio, GETDATE())
        WHERE LogID = @LogID;
        
        PRINT 'Carga de dimensiones completada exitosamente.';
        
    END TRY
    BEGIN CATCH
        -- Manejar error
        UPDATE etl.LogEjecucion
        SET Estado = 'Error',
            FechaFin = GETDATE(),
            MensajeError = ERROR_MESSAGE()
        WHERE LogID = @LogID;
        
        THROW;
    END CATCH
END
\end{lstlisting}

\subsection{B.2 Procedimiento de Carga de Tabla de Hechos - Facturas}

\begin{lstlisting}[
    language=SQL,
    caption={Procedimiento fact.sp\_CargarFactFacturas (fragmento)},
    label={lst:sp_cargar_facturas}
]
CREATE PROCEDURE fact.sp_CargarFactFacturas
    @FechaInicio DATE = NULL,
    @FechaFin DATE = NULL
AS
BEGIN
    SET NOCOUNT ON;
    
    -- Valores por defecto: ultimos 30 dias
    IF @FechaInicio IS NULL
        SET @FechaInicio = DATEADD(DAY, -30, GETDATE());
    IF @FechaFin IS NULL
        SET @FechaFin = GETDATE();
    
    DECLARE @LogID INT;
    DECLARE @RegistrosInsertados INT = 0;
    
    BEGIN TRY
        -- Registrar inicio
        INSERT INTO etl.LogEjecucion (...)
        VALUES ('Carga FactFacturas', GETDATE(), 'En Proceso');
        SET @LogID = SCOPE_IDENTITY();
        
        -- Insertar facturas con calculos de morosidad
        INSERT INTO fact.FactFacturas (
            TiempoFacturaKey,
            ClienteKey,
            ProductoKey,
            -- ... otros campos ...
            V_Total,
            Saldo_Neto,
            Dias_Mora,
            Es_Moroso,
            Rango_Mora
        )
        SELECT 
            t.TiempoKey AS TiempoFacturaKey,
            c.ClienteKey,
            p.ProductoKey,
            -- ... otros campos ...
            f.V_Total,
            f.Saldo_Neto,
            -- Calculo de dias de mora
            CASE 
                WHEN f.Saldo_Neto > 0 
                     AND f.F_Vencimiento < GETDATE()
                THEN DATEDIFF(DAY, f.F_Vencimiento, GETDATE())
                ELSE 0
            END AS Dias_Mora,
            -- Indicador moroso
            CASE 
                WHEN f.Saldo_Neto > 0 
                     AND f.F_Vencimiento < GETDATE()
                THEN 1
                ELSE 0
            END AS Es_Moroso,
            -- Clasificacion rango de mora
            CASE
                WHEN f.Saldo_Neto = 0 
                     OR f.F_Vencimiento >= GETDATE()
                THEN 'Al Dia'
                WHEN DATEDIFF(DAY, f.F_Vencimiento, GETDATE()) 
                     BETWEEN 1 AND 30
                THEN '1-30 dias'
                WHEN DATEDIFF(DAY, f.F_Vencimiento, GETDATE()) 
                     BETWEEN 31 AND 60
                THEN '31-60 dias'
                WHEN DATEDIFF(DAY, f.F_Vencimiento, GETDATE()) 
                     BETWEEN 61 AND 90
                THEN '61-90 dias'
                WHEN DATEDIFF(DAY, f.F_Vencimiento, GETDATE()) 
                     BETWEEN 91 AND 120
                THEN '91-120 dias'
                ELSE '>120 dias'
            END AS Rango_Mora
        FROM staging.syn_V_fac_facturas_enca f
        -- Joins con dimensiones
        INNER JOIN dim.DimTiempo t 
            ON CAST(f.F_Factura AS DATE) = t.Fecha
        INNER JOIN dim.DimCliente c 
            ON f.C_Cod_Cliente = c.C_Cod_Cliente
            AND c.EsRegistroActual = 1
        LEFT JOIN dim.DimProducto p
            ON f.C_Item = p.C_Item
            AND p.EsRegistroActual = 1
        -- ... mas joins ...
        WHERE f.F_Factura BETWEEN @FechaInicio AND @FechaFin
          AND NOT EXISTS (
              SELECT 1 FROM fact.FactFacturas ff
              WHERE ff.N_Documento = f.N_Documento
          );
        
        SET @RegistrosInsertados = @@ROWCOUNT;
        
        -- Actualizar log
        UPDATE etl.LogEjecucion
        SET Estado = 'Completado',
            FechaFin = GETDATE(),
            RegistrosInsertados = @RegistrosInsertados
        WHERE LogID = @LogID;
        
    END TRY
    BEGIN CATCH
        -- Manejo de errores
        UPDATE etl.LogEjecucion
        SET Estado = 'Error',
            MensajeError = ERROR_MESSAGE()
        WHERE LogID = @LogID;
        
        THROW;
    END CATCH
END
\end{lstlisting}

\section{Anexo C: Consultas SQL para Análisis de Morosidad}

\subsection{C.1 Resumen Ejecutivo de Morosidad}

\begin{lstlisting}[
    language=SQL,
    caption={Consulta para resumen ejecutivo de morosidad},
    label={lst:resumen_morosidad}
]
-- Resumen ejecutivo de morosidad
SELECT 
    COUNT(DISTINCT ClienteKey) AS Total_Clientes,
    COUNT(FacturaKey) AS Total_Facturas,
    SUM(V_Total) AS Monto_Total_Facturado,
    SUM(Saldo_Neto) AS Saldo_Total_Pendiente,
    SUM(CASE WHEN Es_Moroso = 1 
        THEN Saldo_Neto ELSE 0 END) AS Saldo_Moroso,
    CAST(SUM(CASE WHEN Es_Moroso = 1 
        THEN Saldo_Neto ELSE 0 END) * 100.0 / 
        NULLIF(SUM(Saldo_Neto), 0) AS DECIMAL(5,2)) 
        AS Porcentaje_Morosidad,
    AVG(CASE WHEN Es_Moroso = 1 
        THEN Dias_Mora ELSE NULL END) AS Dias_Mora_Promedio
FROM fact.FactFacturas
WHERE Saldo_Neto > 0;
\end{lstlisting}

\subsection{C.2 Top 20 Clientes con Mayor Morosidad}

\begin{lstlisting}[
    language=SQL,
    caption={Consulta para identificar clientes con mayor morosidad},
    label={lst:top_morosos}
]
SELECT TOP 20
    c.Cliente,
    c.D_Razon_Social,
    c.Regional,
    c.Vendedor,
    COUNT(f.FacturaKey) AS Facturas_Morosas,
    SUM(f.Saldo_Neto) AS Saldo_Moroso_Total,
    AVG(f.Dias_Mora) AS Promedio_Dias_Mora,
    MAX(f.Dias_Mora) AS Maximo_Dias_Mora
FROM fact.FactFacturas f
INNER JOIN dim.DimCliente c 
    ON f.ClienteKey = c.ClienteKey
WHERE f.Es_Moroso = 1
  AND c.EsRegistroActual = 1
GROUP BY 
    c.Cliente, 
    c.D_Razon_Social, 
    c.Regional, 
    c.Vendedor
ORDER BY SUM(f.Saldo_Neto) DESC;
\end{lstlisting}

\subsection{C.3 Evolución Temporal de Morosidad}

\begin{lstlisting}[
    language=SQL,
    caption={Consulta para análisis de tendencia temporal},
    label={lst:evolucion_temporal}
]
SELECT 
    t.PeriodoAnioMes AS Periodo,
    COUNT(f.FacturaKey) AS Total_Facturas,
    COUNT(CASE WHEN f.Es_Moroso = 1 
        THEN 1 END) AS Facturas_Morosas,
    CAST(COUNT(CASE WHEN f.Es_Moroso = 1 THEN 1 END) 
        * 100.0 / NULLIF(COUNT(f.FacturaKey), 0) 
        AS DECIMAL(5,2)) AS Porcentaje_Morosidad,
    SUM(f.V_Total) AS Monto_Facturado,
    SUM(f.Saldo_Neto) AS Saldo_Pendiente,
    SUM(CASE WHEN f.Es_Moroso = 1 
        THEN f.Saldo_Neto ELSE 0 END) AS Saldo_Moroso
FROM fact.FactFacturas f
INNER JOIN dim.DimTiempo t 
    ON f.TiempoFacturaKey = t.TiempoKey
WHERE t.Fecha >= DATEADD(MONTH, -12, GETDATE())
GROUP BY t.PeriodoAnioMes, t.Anio, t.Mes
ORDER BY t.Anio, t.Mes;
\end{lstlisting}

\subsection{C.4 Análisis de Morosidad por Región Geográfica}

\begin{lstlisting}[
    language=SQL,
    caption={Consulta para análisis geográfico de morosidad},
    label={lst:analisis_regional}
]
SELECT 
    c.Regional,
    COUNT(DISTINCT c.ClienteKey) AS Total_Clientes,
    COUNT(DISTINCT CASE WHEN f.Es_Moroso = 1 
        THEN c.ClienteKey END) AS Clientes_Morosos,
    CAST(COUNT(DISTINCT CASE WHEN f.Es_Moroso = 1 
        THEN c.ClienteKey END) * 100.0 / 
        NULLIF(COUNT(DISTINCT c.ClienteKey), 0) 
        AS DECIMAL(5,2)) AS Porcentaje_Morosidad,
    SUM(CASE WHEN f.Es_Moroso = 1 
        THEN f.Saldo_Neto ELSE 0 END) AS Saldo_Moroso,
    AVG(CASE WHEN f.Es_Moroso = 1 
        THEN f.Dias_Mora END) AS Dias_Mora_Promedio
FROM dim.DimCliente c
LEFT JOIN fact.FactFacturas f 
    ON f.ClienteKey = c.ClienteKey
WHERE c.EsRegistroActual = 1
  AND c.Regional IS NOT NULL
GROUP BY c.Regional
ORDER BY Saldo_Moroso DESC;
\end{lstlisting}


\section{Anexo B: Estructura de la Base de Datos}

\begin{table}[ht]
\centering
\begin{tabular}{|p{4cm}|p{3cm}|p{7cm}|}
\hline
\textbf{Tabla} & \textbf{Descripción} & \textbf{Campos principales} \\
\hline
Clientes & Información básica de clientes & ID\_Cliente, Nombre, Región, Categoría, Fecha\_Ingreso \\
\hline
Transacciones & Registro de ventas & ID\_Transacción, ID\_Cliente, Fecha, Monto, Plazo\_Pago \\
\hline
Pagos & Registro de pagos recibidos & ID\_Pago, ID\_Transacción, Fecha\_Pago, Monto \\
\hline
Variables\_Derivadas & Variables calculadas para el modelo & ID\_Cliente, Antigüedad, Máximo\_Días\_Atraso, Índice\_Estacionalidad \\
\hline
Predicciones & Resultados del modelo predictivo & ID\_Cliente, Fecha\_Predicción, Probabilidad\_Morosidad, Nivel\_Alerta \\
\hline
\end{tabular}
\caption{Estructura de la base de datos del sistema}
\label{tab:estructura_bd}
\end{table}
\section{Anexo C: Configuración del Dashboard}

El siguiente código muestra la configuración principal del dashboard implementado en Power BI para la visualización de resultados del modelo predictivo:

\begin{lstlisting}[language=SQL, caption=Configuración de Power BI para dashboard de riesgo crediticio]
-- Conexión a la fuente de datos
Source = Sql.Database(
    "servidor-sqlserver", 
    "db_riesgo_crediticio",
    [
        User = "usuario_analisis",
        HierarchicalNavigation = true
    ]
)

-- Consulta principal para mapa de riesgo
QueryMapaRiesgo = 
    "SELECT 
        c.Region, 
        COUNT(p.ID_Cliente) as Num_Clientes,
        AVG(p.Probabilidad_Morosidad) as Riesgo_Promedio,
        SUM(CASE WHEN p.Nivel_Alerta = 'Rojo' THEN 1 ELSE 0 END) as Alertas_Rojas
     FROM Clientes c
     JOIN Predicciones p ON c.ID_Cliente = p.ID_Cliente
     WHERE p.Fecha_Prediccion = 
        (SELECT MAX(Fecha_Prediccion) FROM Predicciones)
     GROUP BY c.Region
     ORDER BY Riesgo_Promedio DESC"

-- Configuración de actualización automática
Actualización = 
    Table.AddColumn(
        Source, 
        "Última Actualización", 
        each DateTime.LocalNow()
    )

-- Consulta para tendencias temporales
QueryTendencias = 
    "SELECT 
        CAST(p.Fecha_Prediccion AS DATE) as Fecha,
        AVG(p.Probabilidad_Morosidad) as Riesgo_Promedio_Diario,
        COUNT(*) as Total_Predicciones,
        SUM(CASE WHEN p.Nivel_Alerta IN ('Rojo', 'Naranja') THEN 1 ELSE 0 END) as Alertas_Criticas
     FROM ML_Predicciones p
     WHERE p.Fecha_Prediccion >= DATEADD(day, -30, GETDATE())
     GROUP BY CAST(p.Fecha_Prediccion AS DATE)
     ORDER BY Fecha"

-- Medidas DAX personalizadas
Riesgo_Promedio_Measure = 
    AVERAGE(Predicciones[Probabilidad_Morosidad])

Alertas_Criticas_Count = 
    CALCULATE(
        COUNT(Predicciones[ID_Cliente]),
        Predicciones[Nivel_Alerta] IN {"Rojo", "Naranja"}
    )

Porcentaje_Alto_Riesgo = 
    DIVIDE(
        [Alertas_Criticas_Count],
        COUNT(Predicciones[ID_Cliente]),
        0
    ) * 100
\end{lstlisting}
\section{Anexo D: Resultados Detallados por Segmento}

La tabla siguiente muestra el rendimiento detallado del modelo predictivo segmentado por tipo de cliente, proporcionando métricas específicas para cada categoría:

\begin{table}[ht]
\centering
\begin{tabular}{|p{2.5cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2.5cm}|}
\hline
\textbf{Segmento} & \textbf{Precisión} & \textbf{Recall} & \textbf{F1-Score} & \textbf{AUC} & \textbf{Reducción morosidad} \\
\hline
Premium & 0.92 & 0.89 & 0.90 & 0.95 & 22\% \\
\hline
Estable & 0.85 & 0.82 & 0.83 & 0.90 & 19\% \\
\hline
Estacional & 0.76 & 0.79 & 0.77 & 0.84 & 16\% \\
\hline
Alto riesgo & 0.88 & 0.91 & 0.89 & 0.94 & 14\% \\
\hline
\textbf{Global} & \textbf{0.84} & \textbf{0.82} & \textbf{0.83} & \textbf{0.91} & \textbf{18\%} \\
\hline
\end{tabular}
\caption{Resultados detallados por segmento de cliente}
\label{tab:resultados_segmento}
\end{table}

\subsection{Análisis por Segmento}

\textbf{Segmento Premium:} Presenta el mejor rendimiento con una precisión del 92\% y una reducción de morosidad del 22\%. Esto se debe a patrones de pago más consistentes y mayor estabilidad financiera.

\textbf{Segmento Estable:} Muestra métricas sólidas con un equilibrio entre precisión (85\%) y recall (82\%). La reducción de morosidad del 19\% confirma la efectividad del modelo en este grupo.

\textbf{Segmento Estacional:} Presenta mayor variabilidad debido a la naturaleza cíclica de sus compras, resultando en métricas ligeramente inferiores pero aún aceptables.

\textbf{Segmento Alto Riesgo:} A pesar de ser el grupo más desafiante, el modelo logra un recall del 91\%, crucial para identificar casos problemáticos.
\section{Anexo E: Encuesta de Satisfacción de Usuarios}

Los resultados de la encuesta de satisfacción aplicada a los usuarios del sistema se presentan segmentados por área funcional:

\begin{table}[ht]
\centering
\begin{tabular}{|p{5cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
\textbf{Aspecto evaluado} & \textbf{Gerencia \newline (n=3)} & \textbf{Crédito \newline (n=5)} & \textbf{Cobranzas \newline (n=4)} \\
\hline
Facilidad de uso & 4.3/5 & 4.1/5 & 4.5/5 \\
\hline
Utilidad de predicciones & 4.7/5 & 4.6/5 & 4.8/5 \\
\hline
Claridad de visualizaciones & 4.0/5 & 4.2/5 & 4.3/5 \\
\hline
Impacto en toma de decisiones & 4.3/5 & 4.5/5 & 4.7/5 \\
\hline
Confianza en resultados & 3.7/5 & 4.0/5 & 4.1/5 \\
\hline
\textbf{Satisfacción general} & \textbf{4.2/5} & \textbf{4.3/5} & \textbf{4.5/5} \\
\hline
\end{tabular}
\caption{Resultados de encuesta de satisfacción por grupo de usuarios}
\label{tab:satisfaccion_usuarios}
\end{table}

\subsection{Comentarios Destacados}

\textbf{Área de Gerencia:}
\begin{itemize}
\item ``El sistema proporciona información valiosa para la toma de decisiones estratégicas''
\item ``Las alertas tempranas han mejorado significativamente la gestión de riesgos''
\item ``Recomendamos expandir el sistema a otras áreas de negocio''
\end{itemize}

\textbf{Área de Crédito:}
\begin{itemize}
\item ``La precisión de las predicciones ha superado nuestras expectativas''
\item ``El tiempo de análisis de clientes se ha reducido considerablemente''
\item ``Sugerimos incluir más variables demográficas en futuras versiones''
\end{itemize}

\textbf{Área de Cobranzas:}
\begin{itemize}
\item ``Las alertas nos permiten actuar proactivamente''
\item ``El sistema ha optimizado nuestra estrategia de cobranza''
\item ``La interfaz es intuitiva y fácil de usar''
\end{itemize}
\section{Anexo F: Código de Implementación ETL y Predicción}

A continuación se presenta el código completo del proceso ETL y el sistema de predicción implementado:

\subsection{Script de ETL - Extracción y Transformación}

\begin{verbatim}
# etl_morosidad.py
import pandas as pd
import numpy as np
import pyodbc
from datetime import datetime, timedelta
import logging
from sklearn.preprocessing import StandardScaler, LabelEncoder
import warnings
warnings.filterwarnings('ignore')

# Configuración de logging
logging.basicConfig(level=logging.INFO, 
                   format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ETLMorosidad:
    def __init__(self, config):
        self.config = config
        self.connection = None
        
    def conectar_bd(self):
        """Establece conexión con SQL Server"""
        try:
            connection_string = f"""
            DRIVER={{ODBC Driver 17 for SQL Server}};
            SERVER={self.config['server']};
            DATABASE={self.config['database']};
            UID={self.config['username']};
            PWD={self.config['password']};
            Trusted_Connection=no;
            """
            self.connection = pyodbc.connect(connection_string)
            logger.info("Conexión a base de datos establecida exitosamente")
            return True
        except Exception as e:
            logger.error(f"Error conectando a base de datos: {e}")
            return False
    
    def extraer_datos_clientes(self):
        """Extrae datos maestros de clientes"""
        query = """
        SELECT 
            C_Cod_Cliente as ID_Cliente,
            Cliente as Nombre_Cliente,
            N_Region as Region,
            N_Ciudad as Ciudad,
            F_Ingreso as Fecha_Ingreso,
            C_Tipo_Cliente as Tipo_Cliente,
            Cupo_Facturacion as Cupo_Credito,
            V_Dias_Pago as Dias_Plazo_Pago,
            C_Vendedor as ID_Vendedor,
            C_Zona_Geo as Zona_Geografica
        FROM v_fac_clientes 
        WHERE Flag_Vigente = 1
        """
        
        df_clientes = pd.read_sql(query, self.connection)
        logger.info(f"Extraídos {len(df_clientes)} registros de clientes")
        return df_clientes
    
    def extraer_datos_transaccionales(self, fecha_inicio=None):
        """Extrae datos transaccionales de facturas y pagos"""
        if fecha_inicio is None:
            fecha_inicio = (datetime.now() - timedelta(days=2555)).strftime('%Y-%m-%d')
        
        query_facturas = f"""
        SELECT 
            F.C_Cod_Cliente as ID_Cliente,
            F.F_Factura as Fecha_Factura,
            F.F_Vencimiento as Fecha_Vencimiento,
            F.V_Total as Monto_Factura,
            F.N_Documento as Numero_Factura,
            F.C_Vendedor as ID_Vendedor,
            F.C_Regional as ID_Regional,
            DATEDIFF(day, F.F_Factura, GETDATE()) as Dias_Desde_Factura,
            DATEDIFF(day, F.F_Vencimiento, GETDATE()) as Dias_Vencimiento
        FROM v_fac_facturas_enca F
        WHERE F.F_Factura >= '{fecha_inicio}'
          AND F.Estado_Factura = 1
        """
        
        query_pagos = f"""
        SELECT 
            P.C_Cod_Cliente as ID_Cliente,
            P.F_Documento as Fecha_Pago,
            P.V_Pago_Real as Monto_Pago,
            P.N_Documento as Numero_Recibo,
            F.F_Factura as Fecha_Factura_Origen,
            F.F_Vencimiento as Fecha_Vencimiento_Origen,
            DATEDIFF(day, F.F_Vencimiento, P.F_Documento) as Dias_Atraso
        FROM V_CxC_Pagos_deta P
        INNER JOIN v_fac_facturas_enca F 
            ON P.N_Documento_F = F.N_Documento
        WHERE P.F_Documento >= '{fecha_inicio}'
        """
        
        df_facturas = pd.read_sql(query_facturas, self.connection)
        df_pagos = pd.read_sql(query_pagos, self.connection)
        
        logger.info(f"Extraídas {len(df_facturas)} facturas y {len(df_pagos)} pagos")
        return df_facturas, df_pagos
\end{verbatim}
\begin{verbatim}
def calcular_variables_comportamiento(self, df_facturas, df_pagos):
        """Calcula variables de comportamiento de pago por cliente"""
        
        # Métricas de pago por cliente
        pagos_stats = df_pagos.groupby('ID_Cliente').agg({
            'Dias_Atraso': ['mean', 'max', 'std', 'count'],
            'Monto_Pago': ['sum', 'mean'],
            'Fecha_Pago': ['min', 'max']
        }).round(2)
        
        pagos_stats.columns = [
            'Dias_Atraso_Promedio', 'Dias_Atraso_Maximo', 'Dias_Atraso_Std', 
            'Cantidad_Pagos', 'Monto_Total_Pagado', 'Monto_Promedio_Pago',
            'Primer_Pago', 'Ultimo_Pago'
        ]
        
        # Métricas de facturación por cliente
        facturas_stats = df_facturas.groupby('ID_Cliente').agg({
            'Monto_Factura': ['sum', 'mean', 'count'],
            'Fecha_Factura': ['min', 'max'],
            'Dias_Vencimiento': ['mean', 'max']
        }).round(2)
        
        facturas_stats.columns = [
            'Monto_Total_Facturado', 'Monto_Promedio_Factura', 
            'Cantidad_Facturas', 'Primera_Factura', 'Ultima_Factura',
            'Promedio_Dias_Vencimiento', 'Maximo_Dias_Vencimiento'
        ]
        
        # Calcular variables derivadas
        comportamiento = pagos_stats.join(facturas_stats, how='outer').fillna(0)
        
        # Ratio de cumplimiento
        comportamiento['Ratio_Cumplimiento'] = np.where(
            comportamiento['Cantidad_Facturas'] > 0,
            comportamiento['Cantidad_Pagos'] / comportamiento['Cantidad_Facturas'],
            0
        )
        
        # Indicador de morosidad (target)
        comportamiento['Moroso'] = np.where(
            comportamiento['Dias_Atraso_Maximo'] > 30, 1, 0
        )
        
        # Variabilidad de pagos
        comportamiento['Variabilidad_Pago'] = comportamiento['Dias_Atraso_Std'].fillna(0)
        
        logger.info(f"Variables de comportamiento calculadas para {len(comportamiento)} clientes")
        return comportamiento
    
    def calcular_variables_temporales(self, df_facturas):
        """Calcula variables de estacionalidad y tendencias"""
        
        df_facturas['Mes'] = pd.to_datetime(df_facturas['Fecha_Factura']).dt.month
        df_facturas['Trimestre'] = pd.to_datetime(df_facturas['Fecha_Factura']).dt.quarter
        df_facturas['Año'] = pd.to_datetime(df_facturas['Fecha_Factura']).dt.year
        
        # Índice de estacionalidad por cliente
        estacionalidad = df_facturas.groupby(['ID_Cliente', 'Mes'])['Monto_Factura'].sum().reset_index()
        estacionalidad_stats = estacionalidad.groupby('ID_Cliente')['Monto_Factura'].std().reset_index()
        estacionalidad_stats.columns = ['ID_Cliente', 'Indice_Estacionalidad']
        estacionalidad_stats['Indice_Estacionalidad'] = estacionalidad_stats['Indice_Estacionalidad'].fillna(0)
        
        # Tendencia de compras (últimos 6 meses)
        fecha_corte = datetime.now() - timedelta(days=180)
        df_reciente = df_facturas[pd.to_datetime(df_facturas['Fecha_Factura']) >= fecha_corte]
        
        tendencia = df_reciente.groupby(['ID_Cliente', 'Año', 'Mes'])['Monto_Factura'].sum().reset_index()
        tendencia_stats = tendencia.groupby('ID_Cliente').apply(
            lambda x: np.polyfit(range(len(x)), x['Monto_Factura'], 1)[0] if len(x) > 1 else 0
        ).reset_index()
        tendencia_stats.columns = ['ID_Cliente', 'Tendencia_Compra']
        
        temporal = estacionalidad_stats.merge(tendencia_stats, on='ID_Cliente', how='outer').fillna(0)
        
        logger.info(f"Variables temporales calculadas para {len(temporal)} clientes")
        return temporal
        def unificar_dataset(self, df_clientes, df_comportamiento, df_temporal):
        """Unifica todos los datasets en uno final para ML"""
        
        # Calcular antigüedad en meses
        df_clientes['Fecha_Ingreso'] = pd.to_datetime(df_clientes['Fecha_Ingreso'])
        df_clientes['Antiguedad_Meses'] = (
            (datetime.now() - df_clientes['Fecha_Ingreso']).dt.days / 30.44
        ).round(0)
        
        # Merge de todos los datasets
        dataset_final = df_clientes.merge(
            df_comportamiento, left_on='ID_Cliente', right_index=True, how='left'
        ).merge(
            df_temporal, on='ID_Cliente', how='left'
        ).fillna(0)
        
        # Seleccionar columnas finales para ML
        columnas_ml = [
            'ID_Cliente', 'Region', 'Antiguedad_Meses', 'Cupo_Credito',
            'Dias_Plazo_Pago', 'Monto_Promedio_Factura', 'Cantidad_Facturas',
            'Dias_Atraso_Promedio', 'Dias_Atraso_Maximo', 'Variabilidad_Pago',
            'Ratio_Cumplimiento', 'Indice_Estacionalidad', 'Tendencia_Compra',
            'Moroso'
        ]
        
        dataset_ml = dataset_final[columnas_ml].copy()
        
        # Limpiar valores infinitos y NaN
        dataset_ml = dataset_ml.replace([np.inf, -np.inf], np.nan).fillna(0)
        
        logger.info(f"Dataset final unificado: {len(dataset_ml)} registros, {len(dataset_ml.columns)} variables")
        return dataset_ml
    
    def guardar_dataset(self, dataset, tabla_destino='V_Datos_ML'):
        """Guarda el dataset procesado en SQL Server"""
        try:
            # Truncar tabla existente
            cursor = self.connection.cursor()
            cursor.execute(f"TRUNCATE TABLE {tabla_destino}")
            self.connection.commit()
            
            # Insertar nuevos datos
            for index, row in dataset.iterrows():
                placeholders = ', '.join(['?' for _ in row])
                columns = ', '.join(row.index)
                sql = f"INSERT INTO {tabla_destino} ({columns}) VALUES ({placeholders})"
                cursor.execute(sql, tuple(row))
            
            self.connection.commit()
            cursor.close()
            logger.info(f"Dataset guardado exitosamente en tabla {tabla_destino}")
            
        except Exception as e:
            logger.error(f"Error guardando dataset: {e}")
            self.connection.rollback()
    
    def ejecutar_etl_completo(self):
        """Ejecuta el proceso ETL completo"""
        try:
            logger.info("Iniciando proceso ETL completo")
            
            # Conectar a base de datos
            if not self.conectar_bd():
                return False
            
            # Extraer datos
            df_clientes = self.extraer_datos_clientes()
            df_facturas, df_pagos = self.extraer_datos_transaccionales()
            
            # Procesar datos
            df_comportamiento = self.calcular_variables_comportamiento(df_facturas, df_pagos)
            df_temporal = self.calcular_variables_temporales(df_facturas)
            
            # Unificar dataset
            dataset_final = self.unificar_dataset(df_clientes, df_comportamiento, df_temporal)
            
            # Guardar resultado
            self.guardar_dataset(dataset_final)
            
            logger.info("Proceso ETL completado exitosamente")
            return dataset_final
            
        except Exception as e:
            logger.error(f"Error en proceso ETL: {e}")
            return None
        finally:
            if self.connection:
                self.connection.close()

# Configuración y ejecución
if __name__ == "__main__":
    config = {
        'server': 'servidor-sqlserver',
        'database': 'DW_Comisaseo', 
        'username': 'usuario_analisis',
        'password': 'password'
    }
    
    etl = ETLMorosidad(config)
    resultado = etl.ejecutar_etl_completo()
    
    if resultado is not None:
        print(f"ETL completado. Dataset final: {len(resultado)} registros")
        print(f"Distribución target: {resultado['Moroso'].value_counts()}")
    else:
        print("ETL falló")
\end{verbatim}
\subsection{Sistema de Predicción y Alertas}

\begin{verbatim}
# predictor_morosidad.py
import pandas as pd
import numpy as np
import joblib
import pyodbc
from datetime import datetime
import smtplib
from email.mime.text import MimeText
from email.mime.multipart import MimeMultipart
import logging

class PredictorMorosidad:
    def __init__(self, config):
        self.config = config
        self.modelo = None
        self.connection = None
        self.logger = self._setup_logger()
        
    def _setup_logger(self):
        logging.basicConfig(level=logging.INFO)
        return logging.getLogger(__name__)
    
    def cargar_modelo(self, ruta_modelo='modelo_xgboost_final.pkl'):
        """Carga el modelo entrenado"""
        try:
            self.modelo = joblib.load(ruta_modelo)
            self.logger.info("Modelo cargado exitosamente")
            return True
        except Exception as e:
            self.logger.error(f"Error cargando modelo: {e}")
            return False
    
    def conectar_bd(self):
        """Conecta a la base de datos"""
        try:
            connection_string = f"""
            DRIVER={{ODBC Driver 17 for SQL Server}};
            SERVER={self.config['db_server']};
            DATABASE={self.config['db_name']};
            UID={self.config['db_user']};
            PWD={self.config['db_password']};
            """
            self.connection = pyodbc.connect(connection_string)
            return True
        except Exception as e:
            self.logger.error(f"Error conectando BD: {e}")
            return False
    
    def obtener_datos_prediccion(self):
        """Obtiene datos actualizados para predicción"""
        query = """
        SELECT 
            ID_Cliente,
            Region,
            Antiguedad_Meses,
            Cupo_Credito,
            Dias_Plazo_Pago,
            Monto_Promedio_Factura,
            Cantidad_Facturas,
            Dias_Atraso_Promedio,
            Dias_Atraso_Maximo,
            Variabilidad_Pago,
            Ratio_Cumplimiento,
            Indice_Estacionalidad,
            Tendencia_Compra
        FROM V_Datos_ML
        WHERE ID_Cliente IS NOT NULL
        """
        
        df = pd.read_sql(query, self.connection)
        self.logger.info(f"Datos obtenidos para {len(df)} clientes")
        return df
    
    def generar_predicciones(self, df_datos):
        """Genera predicciones de morosidad"""
        try:
            # Preparar datos (sin la columna target 'Moroso')
            X = df_datos.drop(['ID_Cliente'], axis=1)
            
            # Generar predicciones
            predicciones_prob = self.modelo.predict_proba(X)[:, 1]
            predicciones_clase = self.modelo.predict(X)
            
            # Crear DataFrame de resultados
            resultados = df_datos[['ID_Cliente']].copy()
            resultados['Probabilidad_Morosidad'] = predicciones_prob
            resultados['Prediccion_Moroso'] = predicciones_clase
            resultados['Score_Riesgo'] = (predicciones_prob * 100).round(0).astype(int)
            resultados['Fecha_Prediccion'] = datetime.now()
            
            # Asignar nivel de alerta
            resultados['Nivel_Alerta'] = resultados['Probabilidad_Morosidad'].apply(
                self._asignar_nivel_alerta
            )
            
            self.logger.info(f"Predicciones generadas para {len(resultados)} clientes")
            return resultados
            
        except Exception as e:
            self.logger.error(f"Error generando predicciones: {e}")
            return None
\end{verbatim}
\begin{verbatim}
def _asignar_nivel_alerta(self, probabilidad):
        """Asigna nivel de alerta según probabilidad"""
        if probabilidad >= 0.75:
            return 'Rojo'
        elif probabilidad >= 0.50:
            return 'Naranja'
        elif probabilidad >= 0.20:
            return 'Amarillo'
        else:
            return 'Verde'
    
    def guardar_predicciones(self, df_predicciones):
        """Guarda predicciones en base de datos"""
        try:
            cursor = self.connection.cursor()
            
            # Limpiar predicciones del día
            cursor.execute("""
                DELETE FROM ML_Predicciones 
                WHERE CAST(Fecha_Prediccion AS DATE) = CAST(GETDATE() AS DATE)
            """)
            
            # Insertar nuevas predicciones
            for _, row in df_predicciones.iterrows():
                cursor.execute("""
                    INSERT INTO ML_Predicciones 
                    (ID_Cliente, Fecha_Prediccion, Probabilidad_Morosidad, 
                     Prediccion_Moroso, Score_Riesgo, Nivel_Alerta)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (
                    int(row['ID_Cliente']),
                    row['Fecha_Prediccion'],
                    float(row['Probabilidad_Morosidad']),
                    int(row['Prediccion_Moroso']),
                    int(row['Score_Riesgo']),
                    row['Nivel_Alerta']
                ))
            
            self.connection.commit()
            cursor.close()
            self.logger.info("Predicciones guardadas exitosamente")
            
        except Exception as e:
            self.logger.error(f"Error guardando predicciones: {e}")
            self.connection.rollback()
    
    def generar_alertas(self, df_predicciones):
        """Genera alertas para casos de alto riesgo"""
        alertas_criticas = df_predicciones[
            df_predicciones['Nivel_Alerta'].isin(['Naranja', 'Rojo'])
        ].copy()
        
        if len(alertas_criticas) > 0:
            # Obtener información adicional de clientes
            ids_criticos = "','".join(alertas_criticas['ID_Cliente'].astype(str))
            query_clientes = f"""
            SELECT 
                ID_Cliente,
                Nombre_Cliente,
                Region,
                ID_Vendedor,
                Email_Vendedor
            FROM V_Clientes_Completo
            WHERE ID_Cliente IN ('{ids_criticos}')
            """
            
            df_clientes = pd.read_sql(query_clientes, self.connection)
            alertas_detalle = alertas_criticas.merge(df_clientes, on='ID_Cliente')
            
            # Enviar alertas por email
            self._enviar_alertas_email(alertas_detalle)
            
            self.logger.info(f"Generadas {len(alertas_criticas)} alertas críticas")
        
        return alertas_criticas
    
    def _enviar_alertas_email(self, df_alertas):
        """Envía alertas por email a responsables"""
        try:
            smtp_server = smtplib.SMTP(self.config['smtp_server'], self.config['smtp_port'])
            smtp_server.starttls()
            smtp_server.login(self.config['email_user'], self.config['email_password'])
            
            # Agrupar alertas por vendedor
            for vendedor, alertas_vendedor in df_alertas.groupby('ID_Vendedor'):
                if pd.notna(alertas_vendedor['Email_Vendedor'].iloc[0]):
                    self._crear_enviar_email(smtp_server, alertas_vendedor)
            
            smtp_server.quit()
            self.logger.info("Alertas enviadas por email")
            
        except Exception as e:
            self.logger.error(f"Error enviando emails: {e}")
\end{verbatim}
\begin{verbatim}
def _crear_enviar_email(self, smtp_server, alertas):
        """Crea y envía email de alerta individual"""
        email_destino = alertas['Email_Vendedor'].iloc[0]
        
        msg = MimeMultipart()
        msg['From'] = self.config['email_user']
        msg['To'] = email_destino
        msg['Subject'] = f"Alerta de Morosidad - {len(alertas)} cliente(s) en riesgo"
        
        # Crear contenido HTML
        html_content = self._generar_html_alerta(alertas)
        msg.attach(MimeText(html_content, 'html'))
        
        smtp_server.send_message(msg)
    
    def _generar_html_alerta(self, alertas):
        """Genera contenido HTML para email de alerta"""
        html = f"""
        <html>
        <head>
            <style>
                body {{ font-family: Arial, sans-serif; }}
                .header {{ background-color: #f44336; color: white; padding: 10px; }}
                .content {{ padding: 20px; }}
                .cliente-rojo {{ background-color: #ffebee; border-left: 4px solid #f44336; }}
                .cliente-naranja {{ background-color: #fff3e0; border-left: 4px solid #ff9800; }}
                .tabla {{ width: 100%; border-collapse: collapse; }}
                .tabla th, .tabla td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                .tabla th {{ background-color: #f2f2f2; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h2>[CRITICO] Alerta de Riesgo de Morosidad</h2>
            </div>
            <div class="content">
                <p>Se han identificado <strong>{len(alertas)}</strong> cliente(s) con alto riesgo de morosidad:</p>
                
                <table class="tabla">
                    <tr>
                        <th>Cliente</th>
                        <th>Región</th>
                        <th>Probabilidad</th>
                        <th>Nivel</th>
                        <th>Acción Requerida</th>
                    </tr>
        """
        
        for _, alerta in alertas.iterrows():
            nivel_clase = 'cliente-rojo' if alerta['Nivel_Alerta'] == 'Rojo' else 'cliente-naranja'
            accion = 'Contacto inmediato' if alerta['Nivel_Alerta'] == 'Rojo' else 'Seguimiento prioritario'
            
            html += f"""
                    <tr class="{nivel_clase}">
                        <td>{alerta['Nombre_Cliente']}</td>
                        <td>{alerta['Region']}</td>
                        <td>{alerta['Score_Riesgo']}%</td>
                        <td>{alerta['Nivel_Alerta']}</td>
                        <td>{accion}</td>
                    </tr>
            """
        
        html += """
                </table>
                
                <p><strong>Recomendaciones:</strong></p>
                <ul>
                    <li>[CRITICO] <strong>Rojo:</strong> Contacto inmediato y restricción preventiva</li>
                    <li>[CRITICO] <strong>Naranja:</strong> Contacto en 48h y plan de pago especial</li>
                </ul>
                
                <p>Para más detalles, revise el dashboard de riesgo crediticio.</p>
                <p><em>Sistema de Predicción de Morosidad - Generado automáticamente</em></p>
            </div>
        </body>
        </html>
        """
        return html
\end{verbatim}
\begin{verbatim}
def ejecutar_prediccion_completa(self):
        """Ejecuta el proceso completo de predicción y alertas"""
        try:
            self.logger.info("Iniciando proceso de predicción")
            
            # Cargar modelo y conectar BD
            if not self.cargar_modelo():
                return False
            if not self.conectar_bd():
                return False
            
            # Obtener datos y generar predicciones
            datos = self.obtener_datos_prediccion()
            if datos is None or len(datos) == 0:
                self.logger.warning("No se encontraron datos para predicción")
                return False
            
            predicciones = self.generar_predicciones(datos)
            if predicciones is None:
                return False
            
            # Guardar predicciones
            self.guardar_predicciones(predicciones)
            
            # Generar alertas
            alertas = self.generar_alertas(predicciones)
            
            # Estadísticas del proceso
            stats = {
                'total_clientes': len(predicciones),
                'alto_riesgo': len(predicciones[predicciones['Nivel_Alerta'].isin(['Naranja', 'Rojo'])]),
                'alertas_rojas': len(predicciones[predicciones['Nivel_Alerta'] == 'Rojo']),
                'alertas_naranjas': len(predicciones[predicciones['Nivel_Alerta'] == 'Naranja']),
                'probabilidad_promedio': predicciones['Probabilidad_Morosidad'].mean()
            }
            
            self.logger.info(f"Proceso completado: {stats}")
            return stats
            
        except Exception as e:
            self.logger.error(f"Error en proceso de predicción: {e}")
            return False
        finally:
            if self.connection:
                self.connection.close()

# Script de automatización para ejecución programada
def main():
    """Función principal para ejecución automática"""
    config = {
        'db_server': 'servidor-sqlserver',
        'db_name': 'DW_Comisaseo',
        'db_user': 'usuario_prediccion',
        'db_password': 'password_pred',
        'smtp_server': 'smtp.empresa.com',
        'smtp_port': 587,
        'email_user': 'alertas@empresa.com',
        'email_password': 'email_password'
    }
    
    predictor = PredictorMorosidad(config)
    resultado = predictor.ejecutar_prediccion_completa()
    
    if resultado:
        print(f"Predicción completada exitosamente: {resultado}")
    else:
        print("Error en proceso de predicción")
        exit(1)

if __name__ == "__main__":
    main()
\end{verbatim}
\subsection{Script de Monitoreo del Modelo}

\begin{verbatim}
# monitor_modelo.py
import pandas as pd
import numpy as np
import pyodbc
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import warnings
warnings.filterwarnings('ignore')

class MonitorModelo:
    def __init__(self, config):
        self.config = config
        self.connection = None
        
    def conectar_bd(self):
        """Conecta a la base de datos"""
        connection_string = f"""
        DRIVER={{ODBC Driver 17 for SQL Server}};
        SERVER={self.config['server']};
        DATABASE={self.config['database']};
        UID={self.config['username']};
        PWD={self.config['password']};
        """
        self.connection = pyodbc.connect(connection_string)
        
    def obtener_predicciones_historicas(self, dias_atras=30):
        """Obtiene predicciones históricas para evaluación"""
        fecha_inicio = (datetime.now() - timedelta(days=dias_atras)).strftime('%Y-%m-%d')
        
        query = f"""
        SELECT 
            p.ID_Cliente,
            p.Fecha_Prediccion,
            p.Probabilidad_Morosidad,
            p.Prediccion_Moroso,
            p.Score_Riesgo,
            p.Nivel_Alerta,
            c.Moroso as Morosidad_Real
        FROM ML_Predicciones p
        INNER JOIN V_Datos_ML c ON p.ID_Cliente = c.ID_Cliente
        WHERE p.Fecha_Prediccion >= '{fecha_inicio}'
        ORDER BY p.Fecha_Prediccion DESC
        """
        
        return pd.read_sql(query, self.connection)
    
    def calcular_metricas_rendimiento(self, df_eval):
        """Calcula métricas de rendimiento del modelo"""
        y_true = df_eval['Morosidad_Real']
        y_pred = df_eval['Prediccion_Moroso']
        y_proba = df_eval['Probabilidad_Morosidad']
        
        metricas = {
            'accuracy': accuracy_score(y_true, y_pred),
            'precision': precision_score(y_true, y_pred, zero_division=0),
            'recall': recall_score(y_true, y_pred, zero_division=0),
            'f1_score': f1_score(y_true, y_pred, zero_division=0),
            'total_predicciones': len(df_eval),
            'tasa_positivos_real': y_true.mean(),
            'tasa_positivos_pred': y_pred.mean(),
            'prob_promedio': y_proba.mean()
        }
        
        return metricas
    
    def detectar_drift_datos(self, df_actual, df_referencia):
        """Detecta drift en los datos de entrada"""
        drift_metricas = {}
        
        columnas_numericas = ['Probabilidad_Morosidad', 'Score_Riesgo']
        
        for col in columnas_numericas:
            if col in df_actual.columns and col in df_referencia.columns:
                # Test de Kolmogorov-Smirnov
                from scipy import stats
                ks_stat, p_value = stats.ks_2samp(
                    df_referencia[col].dropna(), 
                    df_actual[col].dropna()
                )
                
                drift_metricas[col] = {
                    'ks_statistic': ks_stat,
                    'p_value': p_value,
                    'drift_detectado': p_value < 0.05,
                    'diferencia_media': df_actual[col].mean() - df_referencia[col].mean()
                }
        
        return drift_metricas

    def generar_reporte_monitoring(self):
        """Genera reporte completo de monitoreo"""
        self.conectar_bd()
        
        # Obtener datos de diferentes períodos
        df_actual = self.obtener_predicciones_historicas(7)   # Última semana
        df_mes = self.obtener_predicciones_historicas(30)     # Último mes
        df_referencia = self.obtener_predicciones_historicas(60)  # Referencia 2 meses
        
        # Calcular métricas
        metricas_actual = self.calcular_metricas_rendimiento(df_actual)
        metricas_mes = self.calcular_metricas_rendimiento(df_mes)
        
        # Detectar drift
        drift_info = self.detectar_drift_datos(df_actual, df_referencia)
        
        # Generar reporte
        reporte = {
            'fecha_reporte': datetime.now(),
            'periodo_evaluacion': '7 días',
            'metricas_actuales': metricas_actual,
            'metricas_mensuales': metricas_mes,
            'drift_detectado': any([info['drift_detectado'] for info in drift_info.values()]),
            'drift_detalles': drift_info,
            'recomendaciones': self._generar_recomendaciones(metricas_actual, drift_info)
        }
        
        self.connection.close()
        return reporte
    
    def _generar_recomendaciones(self, metricas, drift_info):
        """Genera recomendaciones basadas en el análisis"""
        recomendaciones = []
        
        # Evaluar rendimiento
        if metricas['accuracy'] < 0.80:
            recomendaciones.append("ALERTA: Precisión por debajo del umbral (80%). Considerar reentrenamiento.")
        
        if metricas['precision'] < 0.75:
            recomendaciones.append("ALERTA: Alta tasa de falsos positivos. Revisar umbrales de decisión.")
        
        if metricas['recall'] < 0.75:
            recomendaciones.append("ALERTA: Alta tasa de falsos negativos. Ajustar sensibilidad del modelo.")
        
        # Evaluar drift
        for variable, info in drift_info.items():
            if info['drift_detectado']:
                recomendaciones.append(f" Drift detectado en {variable}. Reentrenamiento recomendado.")
        
        # Recomendaciones generales
        if metricas['total_predicciones'] < 100:
            recomendaciones.append(" Pocas predicciones para evaluación robusta. Aumentar período de análisis.")
        
        if not recomendaciones:
            recomendaciones.append("[OK] Modelo funcionando dentro de parámetros normales.")
        
        return recomendaciones

# Ejecución del monitoreo
if __name__ == "__main__":
    config = {
        'server': 'servidor-sqlserver',
        'database': 'DW_Comisaseo',
        'username': 'usuario_monitoreo',
        'password': 'password_monitor'
    }
    
    monitor = MonitorModelo(config)
    reporte = monitor.generar_reporte_monitoring()
    
    print("=== REPORTE DE MONITOREO DEL MODELO ===")
    print(f"Fecha: {reporte['fecha_reporte'].strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Período: {reporte['periodo_evaluacion']}")
    print(f"\nMétricas Actuales:")
    for metrica, valor in reporte['metricas_actuales'].items():
        if isinstance(valor, float):
            print(f"  {metrica}: {valor:.3f}")
        else:
            print(f"  {metrica}: {valor}")
    
    print(f"\nDrift Detectado: {'Sí' if reporte['drift_detectado'] else 'No'}")
    
    print(f"\nRecomendaciones:")
    for rec in reporte['recomendaciones']:
        print(f"  {rec}")
\end{verbatim}
